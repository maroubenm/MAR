\begin{quote}
 
\centering

    {
\huge 

GENERAL  INTRODUCTION 

}
\end{quote}


\vspace{1.5cm}

Hand gesture recognition  has gotten and still getting the researchers' attention and focus especially with the current HCI ( Human computer interaction ) evolution that provided Hardware -software  combination that is fast and suitable to interact with humans for a better HCI experience , and since there is a high need of silent communication using sign language for people with speech or  hearing  deficiencies/difficulties or in some cases both , additionally , there are situations when silent communication is preferred : for example , during a surgery,  a doctor may gesture to the nurse for assistance ,Hence making a real time  hand gesture recognition system has become inevitable.

Traditionally , gesture recognition requires high quality stereoscopic cameras with complicated computer vision algorithms to recognize hand signals ,which usually doesn't end to be as interactive as required and of course it requires extensive and expensive setup. but thanks to Microsoft  Kinect, we now can have  an inexpensive  sensors  that helps in having a good user experience in real time .

Microsoft released the first Beta of the Kinect software development kit for Windows 7. This SDK was meant to allow developers to write Kinecting apps by using Microsoft Visual studio including features like accessing Low-level streams from the depth sensor , RGB camera sensor   as well as skeletal  tracking, however,  there  is no hand  specific  data  available for  gesture   recognition,   although    it   includes   information  of the  joints   between  hands   and  arms.

Previous   researches  \ref{chapter1}  on  computer   vision  and hand   detection   have established   solid  groundwork    for gesture   recognition, but  only  a  few  Kinect based   systems  were  developed   for  HGR    and  only  a  few  gestures were recognized . and that is  the main motive behind This Project basing our work on a novel method for contact-less HGR using both bare hands or just  one hand, the system is able to detect hand gestures  made by user , track it  in a range of [ 80 cm until 3meters ] long  and  recognize the meanings of gestures, the real power of the system is its ability to give high accuracy  despite the lighting  conditions,   skin color, clothing,  and background.

Two major approaches were implemented in this project ,  based on Features extractions and Machine learning , the first approach  is  Surf(Speeded up robust features) Features Trained with both K-means And SVM(Support Vector Machine ) , the second approach  based on Fouriere  shape descriptor  features using Nearest neighbor Classifier . Note more details about the implementation are going to be discussed in Chapter \ref{hgr} .

For these purposes we will be studying  Some of the famous Image local Descriptors like ( Sift and Surf )  in chapter  \ref{descriptors}   to familiarize with some of their key words like ( \textbf{keypoints localization , orientation assignment , keypoint descriptor} ..)  and  then  reviewing shape feature extraction using Fouriere descriptor and Covariance matrix approach in  section [\ref{FDT}] , and Finally we are going to Explore  Some of the main ideas behind the success of our learning algorithms and their robustness for our HGR system  in chapter [\ref{ML}].

In the next Chapter we will go through Some of the famous approaches in  Literature about HGR  System , hoping this Chapter will give  credits  to researchers behind a lot of success for this Project .




